{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Archeo\n",
        "\n"
      ],
      "metadata": {
        "id": "2p3BQeqhpwC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Training the model"
      ],
      "metadata": {
        "id": "gFEAYIshp9ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.1Caricamento di path e librerie, oltre allo scheletro della configurazione del modello"
      ],
      "metadata": {
        "id": "Hxq9RgqHqEDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rich\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations import pytorch\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.callbacks import TQDMProgressBar, RichProgressBar\n",
        "\n",
        "import segmentation_models_pytorch  as smp\n",
        "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "\n",
        "PATH_LOG='/exp_logs/'\n",
        "PATH_DATASETS='/datasets/'\n",
        "modelli=['bing_1k','bing_1k_filtrato','bing+corona_1k','bing+corona_2k_filtrato',\n",
        "         'bing_2k','bing_2k_filtrato']\n",
        "testset_modelli={}\n",
        "\n",
        "config = {\n",
        "    \"timestamp\" : datetime.now().strftime(\"%d-%m-%Y_%H%M%S\"),\n",
        "    \"dataset_path\" : \"\",\n",
        "    \"checkpoint_path\":PATH_LOG,\n",
        "    \"random_seed\" : 1234,\n",
        "    \"arch\":\"MAnet\", #Unet,MAnet\n",
        "    \"encoder\":\"efficientnet-b3\", #resnet18, dpn68, efficientnet-b3\n",
        "    \"weights\":\"imagenet\",\n",
        "    \"loss\":\"focal\",\n",
        "    \"learning_rate\":0.0001,\n",
        "    \"precision\":32,\n",
        "    \"epochs\":20,\n",
        "    \"batch_size\":32,\n",
        "    \"corona_path\":\"\",\n",
        "    \"dim_input\":'',\n",
        "    \"in_channels\":0\n",
        "}\n",
        "\n",
        "random.seed(config[\"random_seed\"])\n",
        "np.random.seed(config[\"random_seed\"])\n",
        "torch.manual_seed(config[\"random_seed\"])\n"
      ],
      "metadata": {
        "id": "6ZrWVv32S8I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2 Divisione del dataset in train set (80%), validation set (10%) e test set (10%)"
      ],
      "metadata": {
        "id": "-LFnjlL2qP8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(PATH,SEED,indices):\n",
        "    root_directory = os.path.join(PATH)\n",
        "    images_directory = os.path.join(root_directory, \"train/sites\")\n",
        "    masks_directory = os.path.join(root_directory, \"train/masks\")\n",
        "    \n",
        "    filenames_train = np.asarray(list(sorted(os.listdir(images_directory))))\n",
        "    print(\"total files:\",len(filenames_train))\n",
        "\n",
        "    valid_split = -int(len(indices)*0.2)\n",
        "    test_split = valid_split//2\n",
        "    \n",
        "    train_indices = indices[:valid_split]\n",
        "    valid_indices = indices[valid_split:test_split]\n",
        "    test_indices = indices[test_split:]\n",
        "    train_images_filenames = filenames_train[train_indices]\n",
        "    val_images_filenames = filenames_train[valid_indices]\n",
        "    test_images_filenames = filenames_train[test_indices]\n",
        "\n",
        "    print(\"root:\",root_directory,\"\\nimages\",images_directory,\n",
        "          \"\\nmasks\",masks_directory,\"\\n---\",\n",
        "          '\\ntrain images',len(train_images_filenames), \n",
        "          '\\nval images',len(val_images_filenames), \n",
        "          '\\ntest images',len(test_images_filenames),\n",
        "          '\\n---\\ntotal images',len(filenames_train)\n",
        "         )\n",
        "    \n",
        "    print(\"empty masks percentage: %.4f %.4f %.4f\" % \n",
        "          (np.sum([i.startswith(\"neg\") for i in train_images_filenames])/len(train_images_filenames),\n",
        "            np.sum([i.startswith(\"neg\") for i in val_images_filenames])/len(val_images_filenames),\n",
        "            np.sum([i.startswith(\"neg\") for i in test_images_filenames])/len(test_images_filenames)\n",
        "          ))\n",
        "    \n",
        "    return images_directory, masks_directory, train_images_filenames,\n",
        "            val_images_filenames,test_images_filenames"
      ],
      "metadata": {
        "id": "oxsYae5BYFpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Crop e resize dipendono dalla dimensione dell'input \n",
        "def esegui_trasformazioni():\n",
        "  if(config[\"dim_input\"]=='1k' and config['corona_path']!=\"\"): #stesso crop per input bing e input corona\n",
        "    train_transform = A.Compose([\n",
        "            A.RandomCrop(512,512,p=1.0),\n",
        "            A.Flip(p=0.25),A.RandomRotate90(p=0.25),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.25),\n",
        "            A.Resize(256, 256),\n",
        "            A.pytorch.ToTensorV2(),\n",
        "        ],\n",
        "        additional_targets={'image_corona': 'image'})\n",
        "  \n",
        "\n",
        "    val_transform = A.Compose([\n",
        "            A.RandomCrop(512,512,p=1.0),\n",
        "            A.Resize(256, 256),\n",
        "            A.pytorch.ToTensorV2()\n",
        "        ],\n",
        "        additional_targets={'image_corona': 'image'})\n",
        "  elif(config[\"dim_input\"]=='1k' and config['corona_path']==\"\"):\n",
        "        train_transform = A.Compose([\n",
        "            A.RandomCrop(512,512,p=1.0),\n",
        "            A.Flip(p=0.25),A.RandomRotate90(p=0.25)\n",
        "            ,A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.25),\n",
        "            A.Resize(256, 256),\n",
        "            A.pytorch.ToTensorV2(),\n",
        "        ])\n",
        "     \n",
        "        val_transform = A.Compose([\n",
        "            A.RandomCrop(512,512,p=1.0),\n",
        "            A.Resize(256, 256),\n",
        "            A.pytorch.ToTensorV2()\n",
        "        ])\n",
        "\n",
        "  elif(config[\"dim_input\"]=='2k' and config['corona_path']!=\"\"):\n",
        "    train_transform = A.Compose([\n",
        "            A.RandomCrop(1024,1024,p=1.0),\n",
        "            A.Flip(p=0.25),A.RandomRotate90(p=0.25)\n",
        "            ,A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.25),\n",
        "            A.Resize(512, 512),\n",
        "            A.pytorch.ToTensorV2(),\n",
        "        ],\n",
        "        additional_targets={'image_corona': 'image'})\n",
        "  \n",
        "    val_transform = A.Compose([\n",
        "            A.RandomCrop(1024,1024,p=1.0),\n",
        "            A.Resize(512, 512),\n",
        "            A.pytorch.ToTensorV2()\n",
        "        ],\n",
        "        additional_targets={'image_corona': 'image'})\n",
        "  else:\n",
        "    train_transform = A.Compose([\n",
        "            A.RandomCrop(1024,1024,p=1.0),\n",
        "            A.Flip(p=0.25),A.RandomRotate90(p=0.25)\n",
        "            ,A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.25),\n",
        "            A.Resize(512, 512),\n",
        "            A.pytorch.ToTensorV2(),\n",
        "        ])\n",
        "  \n",
        "    val_transform = A.Compose([\n",
        "            A.RandomCrop(1024,1024,p=1.0),\n",
        "            A.Resize(512, 512),\n",
        "            A.pytorch.ToTensorV2()\n",
        "        ])\n",
        "  return train_transform,val_transform\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "M3UX56KZM6KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.3 Loading the dataset with its transformations"
      ],
      "metadata": {
        "id": "VfgisvZxqlWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Carico il dataset con le relative trasformazioni, in base al tipo di modello che stiamo analizzando,\n",
        "#cio√® in base alla dimensione di input di ogni immagine e ai canali di input. \n",
        "class ArcheoDataset(Dataset):\n",
        "    def __init__(self, images_filenames, images_directory, masks_directory, transform=None):\n",
        "        self.images_filenames = images_filenames\n",
        "        self.images_directory = images_directory\n",
        "        self.masks_directory = masks_directory\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images_filenames)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_filename = self.images_filenames[idx]\n",
        "        image_path = os.path.join(self.images_directory, image_filename)\n",
        "        mask_path = os.path.join(self.masks_directory, image_filename.replace(\".jpg\", \".png\"))\n",
        "        \n",
        "        image = np.array(Image.open(image_path))#.convert(\"RGB\"))\n",
        "        image = Image.open(image_path)\n",
        "      \n",
        "        \n",
        "        mask = ~np.array(Image.open(mask_path).convert(\"L\")) # convert to greyscale (1 channel) masks are flipped because of qgis\n",
        "        mask = mask.astype(\"float\")\n", #convert to float data type\n"
        "        mask[mask > 0.0] = 1.0\n", #convert to binary mask (where structures are 1 and background = 0)\n"
        "        mask = np.expand_dims(mask, -1) #adds another dimension to the tensor\n",
        "\n",
        "\n",
        "        if(config['corona_path']!=\"\"):\n",
        "          path_corona=config['corona_path']\n",
        "          image_path_corona=os.path.join(path_corona, image_filename)\n",
        "          image_corona =np.array(Image.open(image_path_corona))\n",
        "          image_corona = Image.open(image_path_corona)\n",
        "          transformed = self.transform(image=np.asarray(image),\n",
        "                                       image_corona=np.asarray(image_corona),\n",
        "                                       mask=np.asarray(mask))\n",
        "          image_corona=transformed[\"image_corona\"]\n",
        "          image = transformed[\"image\"]\n",
        "          image=torch.cat((image, image_corona), 0)\n",
        "      \n",
        "        else:\n",
        "          transformed = self.transform(image=np.asarray(image),mask=np.asarray(mask)) #convert image to a numpy array\n",
        "          image = transformed[\"image\"]\n",
        "\n",
        "        \n",
        "        mask = transformed[\"mask\"].permute(2,0,1) #permute dimensions \n",
        "        \n",
        "            \n",
        "        return image, mask, image_filename\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vIEBqKiVYlLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.4 Inizializzazione del modello"
      ],
      "metadata": {
        "id": "iwtR-1gPpd19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialisation of the model, calculation of the loss function on the mask, probabilities obtained \n",
        "#with the sigmoid. Probabilities greater than 0.5 are transformed into 1, those below 0.5 into 0.  \n",
        "class ArcheoModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, arch, encoder_name, in_channels, out_classes, **kwargs):\n",
        "        super().__init__()\n",
        "        self.model = smp.create_model(\n",
        "            arch, encoder_name=encoder_name, in_channels=in_channels, classes=out_classes, **kwargs\n",
        "        )\n",
        "        params = smp.encoders.get_preprocessing_params(encoder_name)\n",
        "        self.register_buffer(\"std\", torch.tensor(params[\"std\"]).view(1, 3, 1, 1))\n",
        "        self.register_buffer(\"mean\", torch.tensor(params[\"mean\"]).view(1, 3, 1, 1))\n",
        "        \n",
        "        if config[\"loss\"] == \"jaccard\":\n",
        "            self.loss_fn = smp.losses.JaccardLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "        if config[\"loss\"] == \"dice\":\n",
        "            self.loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "        if config[\"loss\"] == \"focal\":\n",
        "            self.loss_fn = smp.losses.FocalLoss(mode=smp.losses.BINARY_MODE)\n",
        "        \n",
        "\n",
        "    def forward(self, image):\n",
        "        \n",
        "        if(config['corona_path']!=''):\n",
        "          image1,image2=torch.tensor_split(image, 2, dim=1)\n",
        "          image1 = (image1 - self.mean) / self.std\n",
        "          image2 = (image2 - self.mean) / self.std\n",
        "          image=torch.cat((image1, image2), 1)\n",
        "        else:\n",
        "          image = (image - self.mean) / self.std\n",
        "        mask = self.model(image)\n",
        "        return mask\n",
        "\n",
        "    def shared_step(self, batch, stage):\n",
        "        image = batch[0]\n",
        "        assert image.ndim == 4\n",
        "        h, w = image.shape[2:]\n",
        "        assert h % 32 == 0 and w % 32 == 0\n",
        "        mask = batch[1]\n",
        "        assert mask.ndim == 4\n",
        "        assert mask.max() <= 1.0 and mask.min() >= 0\n",
        "        logits_mask = self.forward(image)\n",
        "        loss = self.loss_fn(logits_mask, mask)\n",
        "        self.log_dict({f\"{stage}/loss\": loss.detach().item()},batch_size=config[\"batch_size\"])\n",
        "        prob_mask = logits_mask.sigmoid()\n",
        "        pred_mask = (prob_mask > 0.5).float()  \n",
        "        pred_mask = pred_mask.permute(0,3,1,2)\n",
        "        mask = mask.permute(0,3,1,2)\n",
        "        \n",
        "        tp, fp, fn, tn = smp.metrics.get_stats(pred_mask.long(), mask.long(), mode=\"binary\")\n",
        "        \n",
        "        if stage == \"train\":\n",
        "            self.log_dict({\n",
        "                \"train/batch-IOU-img\":smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro-imagewise\"),\n",
        "                \"train/batch-IOU\":smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\")\n",
        "            }, prog_bar=True, batch_size=config[\"batch_size\"])\n",
        "\n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"tp\": tp,\n",
        "            \"fp\": fp,\n",
        "            \"fn\": fn,\n",
        "            \"tn\": tn,\n",
        "        }\n",
        "\n",
        "    def shared_epoch_end(self, outputs, stage):\n",
        "        tp = torch.cat([x[\"tp\"] for x in outputs])\n",
        "        fp = torch.cat([x[\"fp\"] for x in outputs])\n",
        "        fn = torch.cat([x[\"fn\"] for x in outputs])\n",
        "        tn = torch.cat([x[\"tn\"] for x in outputs])\n",
        "\n",
        "        per_image_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro-imagewise\")\n",
        "        dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\")\n",
        "\n",
        "        metrics = {\n",
        "            f\"{stage}/IOU-img\": per_image_iou,\n",
        "            f\"{stage}/IOU\": dataset_iou,\n",
        "        }\n",
        "        \n",
        "        self.log_dict(metrics, prog_bar=True,batch_size=config[\"batch_size\"])\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.shared_step(batch, \"train\")            \n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        return self.shared_epoch_end(outputs, \"train\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.shared_step(batch, \"valid\")\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        return self.shared_epoch_end(outputs, \"valid\")\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self.shared_step(batch, \"test\")  \n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        return self.shared_epoch_end(outputs, \"test\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=config[\"learning_rate\"]) # 0.00005\n"
      ],
      "metadata": {
        "id": "XS145rxzbrY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_config(name_modello):\n",
        "  config[\"dataset_path\"]=PATH_DATASETS+name_modello\n",
        "  if '1k' in name_modello:\n",
        "    config[\"dim_input\"]='1k'\n",
        "    if('+' in name_modello):\n",
        "      config[\"dataset_path\"]=PATH_DATASETS+'bing_1k/'\n",
        "      config['corona_path']=PATH_DATASETS+'corona_1k/train/sites/'\n",
        "      config['in_channels']=6\n",
        "    else:\n",
        "      config['corona_path']=\"\"\n",
        "      config['in_channels']=3\n",
        "  else:\n",
        "    config[\"dim_input\"]='2k'\n",
        "    if('+' in name_modello):\n",
        "      config['corona_path']=PATH_DATASETS+'corona_2k_filtrato/train/sites/'\n",
        "      config['in_channels']=6\n",
        "      config[\"dataset_path\"]=PATH_DATASETS+'bing_2k_filtrato/'\n",
        "    else:\n",
        "      config['corona_path']=\"\"\n",
        "      config['in_channels']=3"
      ],
      "metadata": {
        "id": "-xl-quxvE3Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.5 Training of each model according to its characteristics"
      ],
      "metadata": {
        "id": "gorxvbn7rFnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Each model is trained according to its characteristics. \n",
        "for i in range(len(modelli)):\n",
        "  set_config(modelli[i])\n",
        "  filenames_train = np.asarray(list(sorted(os.listdir(os.path.join(config[\"dataset_path\"], \"train/sites\")))))\n",
        "  print(\"total files:\",len(filenames_train))\n",
        "  indices = np.arange(0,len(filenames_train))\n",
        "  np.random.shuffle(indices)\n",
        "  print(indices)\n",
        "  \n",
        "\n",
        "  images_directory, masks_directory, train_images_filenames,val_images_filenames,test_images_filenames = \n",
        "  load_dataset(config[\"dataset_path\"],config[\"random_seed\"])\n",
        "  train_transform,val_transform=esegui_trasformazioni()\n",
        "  train_dataset = ArcheoDataset(train_images_filenames, images_directory, \n",
        "                                masks_directory,transform=train_transform)\n",
        "  val_dataset = ArcheoDataset(val_images_filenames, images_directory, \n",
        "                              masks_directory, transform=val_transform)\n",
        "  train_loader = DataLoader(train_dataset,batch_size=config[\"batch_size\"], \n",
        "                            shuffle=True,drop_last=True,num_workers=0,)\n",
        "  val_loader = DataLoader(val_dataset,batch_size=config[\"batch_size\"], \n",
        "                          shuffle=False,drop_last=False,num_workers=0,)\n",
        "  model = ArcheoModel(config[\"arch\"],encoder_name=config[\"encoder\"],\n",
        "                      encoder_weights=config[\"weights\"],\n",
        "                      in_channels=config['in_channels'], \n",
        "                      out_classes=1,) #creazione del modello\n",
        "\n",
        "#TRAINING DEL MODELLO\n",
        "\n",
        "  trainer = pl.Trainer(\n",
        "    max_epochs=config[\"epochs\"],\n",
        "    precision=config[\"precision\"],\n",
        "    accelerator=\"gpu\",\n",
        "    logger=pl_loggers.TensorBoardLogger(config[\"checkpoint_path\"]),\n",
        "    log_every_n_steps=1,\n",
        "    enable_progress_bar=True,\n",
        "    callbacks=[RichProgressBar(refresh_rate=1)],\n",
        "   \n",
        "  )\n",
        "  cfg_text = \"\\n\".join([ str(key)+\" : **\"+str(config[key])+\"**  \" for key in config])\n",
        "  print(cfg_text)\n",
        "  trainer.logger.experiment.add_text(tag=\"config\",text_string=cfg_text)\n",
        "\n",
        "  trainer.fit(\n",
        "    model,\n",
        "    train_dataloaders=train_loader, \n",
        "    val_dataloaders=val_loader)\n",
        "  os.rename(PATH_LOG+'lightning_logs/version_0', PATH_LOG+'lightning_logs/'+modelli[i])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5peABn__byW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 Test di ogni modello\n"
      ],
      "metadata": {
        "id": "THEwd9-GrQwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pytorch_lightning.loggers import tensorboard\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=PATH_LOG"
      ],
      "metadata": {
        "id": "NTsZfXkFdiEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 tests, with different transformations, for each model. \n",
        "iou_test_modelli={}\n",
        "for i in range(len(modelli)):\n",
        "  set_config(modelli[i])\n",
        " \n",
        "  filenames_train = np.asarray(list(sorted(os.listdir(\n",
        "      os.path.join(config[\"dataset_path\"], \"train/sites\")))))\n",
        "  print(\"total files:\",len(filenames_train))\n",
        "  indices = np.arange(0,len(filenames_train))\n",
        "  np.random.shuffle(indices)\n",
        "  print(indices)\n",
        "  \n",
        "  \n",
        " \n",
        "  name_ckpt = os.listdir(PATH_LOG+'lightning_logs/'+modelli[i]+'/checkpoints/')[0]\n",
        "  model = ArcheoModel.load_from_checkpoint(arch=config[\"arch\"],\n",
        "                 encoder_name=config[\"encoder\"], \n",
        "                 encoder_weights=config[\"weights\"],\n",
        "                 in_channels=config['in_channels'], \n",
        "                 out_classes=1,\n",
        "                 checkpoint_path=PATH_LOG+'lightning_logs/'+modelli[i]+'/checkpoints/'+name_ckpt)\n",
        "  print(config['dataset_path'])\n",
        "  images_directory, masks_directory, train_images_filenames,\n",
        "  val_images_filenames,test_images_filenames = load_dataset(config[\"dataset_path\"],\n",
        "                                                            config[\"random_seed\"],indices)\n",
        "  \n",
        "  testiou=[]\n",
        "  for j in range(10):\n",
        "    print(\"Risultato \"+str(j)+\" del modello \"+modelli[i])\n",
        "    train_transform,val_transform=esegui_trasformazioni()\n",
        "    test_dataset = ArcheoDataset(test_images_filenames, images_directory, \n",
        "                                 masks_directory, transform=val_transform)\n",
        "    test_loader = DataLoader(test_dataset,batch_size=config[\"batch_size\"],\n",
        "                             shuffle=False,drop_last=False,num_workers=0,)\n",
        "\n",
        "    trainer = pl.Trainer(gpus=1, max_epochs=40,auto_scale_batch_size=\"binsearch\",\n",
        "                         precision=16,accelerator=\"auto\",)\n",
        " \n",
        "    test_metrics = trainer.test(model, dataloaders=test_loader, verbose=True)\n",
        "    testiou.append(test_metrics[0]['test/IOU-img'])\n",
        "  iou_test_modelli[modelli[i]]=testiou"
      ],
      "metadata": {
        "id": "pYBPlPw9BTOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I print statistics for each model (mean,min,max,std)\n",
        "for i in modelli:\n",
        "  x=np.array(iou_test_modelli[i])\n",
        "  print(\"Le statistiche sul test set per il modello \"+i+\" sono:\")\n",
        "  print(\"media:\"+str(round(x.mean(),4))+\" | min:\"+str(round(x.min(),4))\n",
        "    +\" | max:\"+str(round(x.max(),4))+\" | std:\"+str(round(x.std(),4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm0RObDA_BPA",
        "outputId": "cb33e9a8-7d60-453c-caab-dafaeeebc366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le statistiche sul test set per il modello bing_1k sono:\n",
            "media:0.7417 | min:0.7356 | max:0.7468 | std:0.0038\n",
            "Le statistiche sul test set per il modello bing_1k_filtrato sono:\n",
            "media:0.781 | min:0.7689 | max:0.788 | std:0.0054\n",
            "Le statistiche sul test set per il modello bing+corona_1k sono:\n",
            "media:0.7406 | min:0.7347 | max:0.746 | std:0.0039\n",
            "Le statistiche sul test set per il modello bing+corona_2k_filtrato sono:\n",
            "media:0.8345 | min:0.8312 | max:0.8376 | std:0.0018\n",
            "Le statistiche sul test set per il modello bing_2k sono:\n",
            "media:0.7977 | min:0.7929 | max:0.8031 | std:0.0034\n",
            "Le statistiche sul test set per il modello bing_2k_filtrato sono:\n",
            "media:0.8154 | min:0.8087 | max:0.8223 | std:0.0035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3 Evaluation Models"
      ],
      "metadata": {
        "id": "nxyJKE2ZVQEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Uploading csv's containing site coordinates"
      ],
      "metadata": {
        "id": "WDsztoQgZnBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "namesite2Centroid={}\n",
        "nameneg2Centroid={}\n",
        "namemaysan2Centroid={}\n",
        "name2min={}\n",
        "\n",
        "\n",
        "with open('trainset1000.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "      namesite2Centroid[row[2]]=[row[3],row[4]]\n",
        "      \n",
        "\n",
        "with open('negs1000.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        nameneg2Centroid[row[5]]=[row[3],row[4]]\n",
        "\n",
        "\n",
        "with open('maysan1000.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        namemaysan2Centroid[row[1]]=[row[2],row[3]]\n",
        "\n"
      ],
      "metadata": {
        "id": "0We15_RvVWOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2 Loading the dataset by applying predefined transformations to it\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TZ31iVC-ZvJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ArcheoDatasetModify(Dataset):\n",
        "    def __init__(self, images_filenames, images_directory, masks_directory):\n",
        "        self.images_filenames = images_filenames\n",
        "        self.images_directory = images_directory\n",
        "        self.masks_directory = masks_directory\n",
        "     \n",
        "    def __len__(self):\n",
        "        return len(self.images_filenames)\n",
        "\n",
        "    def __getitem__(self, idx, verbose=False):\n",
        "      image_filename = self.images_filenames[idx]+'.jpg'\n",
        "      image_path = os.path.join(self.images_directory, image_filename)\n",
        "      mask_path = os.path.join(self.masks_directory, \n",
        "                               image_filename.replace(\".jpg\", \".png\"))\n",
        "        \n",
        "      image = np.array(Image.open(image_path))#.convert(\"RGB\"))\n",
        "      image = Image.open(image_path)\n",
        "      # masks are flipped because of qgis\n",
        "      mask = ~np.array(Image.open(mask_path).convert(\"L\")) \n",
        "      mask = mask.astype(\"float\")\n",
        "      mask[mask > 0.0] = 1.0\n",
        "      mask = np.expand_dims(mask, -1)\n",
        "      x_minore=int(name2tras[image_filename[:-4]][0])\n",
        "      y_minore=int(name2tras[image_filename[:-4]][1])\n",
        "      if(config['corona_path']!=''):     \n",
        "        path_corona=config['corona_path']\n",
        "        image_path_corona=os.path.join(path_corona, image_filename)\n",
        "        image_corona =np.array(Image.open(image_path_corona))\n",
        "        image_corona = Image.open(image_path_corona)\n",
        "  \n",
        "        trasformazione = A.Compose([\n",
        "            A.Crop(x_min=x_minore, y_min=y_minore, \n",
        "                   x_max=x_minore+1024, y_max=y_minore+1024,p=1.0),\n",
        "            A.Resize(512,512),\n",
        "            A.pytorch.ToTensorV2()],additional_targets={'image_corona': 'image'})\n",
        "        transformed = trasformazione(image=np.asarray(image),\n",
        "                                     image_corona=np.asarray(image_corona),\n",
        "                                     mask=np.asarray(mask))\n",
        "        image_corona=transformed[\"image_corona\"]\n",
        "        image = transformed[\"image\"]\n",
        "        image=torch.cat((image, image_corona), 0)\n",
        "      \n",
        "      else:\n",
        "        trasformazione = A.Compose([\n",
        "            A.Crop(x_min=x_minore, y_min=y_minore, \n",
        "                   x_max=x_minore+1024, y_max=y_minore+1024,p=1.0),\n",
        "            A.Resize(512,512),\n",
        "            A.pytorch.ToTensorV2()])\n",
        "        transformed = trasformazione(image=np.asarray(image),\n",
        "                                     mask=np.asarray(mask))\n",
        "        image = transformed[\"image\"]\n",
        "\n",
        "      mask = transformed[\"mask\"].permute(2,0,1)\n",
        "      return image, mask, image_filename"
      ],
      "metadata": {
        "id": "g4tHQ6NpYgnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.3 Saving individual predictions"
      ],
      "metadata": {
        "id": "uSN2bOPoZ_1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import gaussian_filter\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#data la predizione,viene applicato un cutoff\n",
        "def stampa_predizioni_cutoff(ibatch,ipr_masks_11,num,nome_modello,val):\n",
        "    for i,(image, gt_mask, masks_11, fn) in enumerate(zip(ibatch[0], ibatch[1], \n",
        "                                                          ipr_masks_11, ibatch[2])):\n",
        "      masks_11 = masks_11.numpy().squeeze()\n",
        "      # cutoff\n",
        "      cf = masks_11.copy()\n",
        "      cf = gaussian_filter(cf, sigma=5)\n",
        "      cf = ((cf + 0.5)**2) - 0.5\n",
        "      cf[cf<=val] = 0.0\n",
        "      cf[cf>val] = 1.0\n",
        "\n",
        "\n",
        "      plt.imsave('/output/'+nome_modello+'/pred_siti_tronc'+\n",
        "                 str(val)+'/'+ fn[:-4]+'.png',cf, cmap=\"magma\", vmin=0.0, vmax=1.0)\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "DvYGKQorZkSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.4 Given the predictions for each site, I create the corresponding tif and shapefiles"
      ],
      "metadata": {
        "id": "izYHcVUK2fqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dato la predizione, viene creato il tif associato. \n",
        "import rasterio\n",
        "def createTif(ovest,sud,est,nord,patin,patout):\n",
        "  dataset = rasterio.open(patin, 'r')\n",
        "  bands = [1, 2, 3]\n",
        "  data = dataset.read(bands)\n",
        "  transform = rasterio.transform.from_bounds(ovest, sud, est, nord, data.shape[2], data.shape[1])\n",
        "  crs = {'init': 'epsg:3857'}\n",
        "\n",
        "  with rasterio.open(patout, 'w', driver='GTiff',\n",
        "                   width=data.shape[2], height=data.shape[1],\n",
        "                   count=3, dtype=data.dtype, nodata=0,\n",
        "                   transform=transform, crs=crs) as dst:\n",
        "      dst.write(data, indexes=bands)"
      ],
      "metadata": {
        "id": "tWXX71yiiSPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ricostruisco la predizione usando le trasformazioni salvate in precedenza.\n",
        "def convertImageToTif(nome_modello,val_tronc,path_pred,path_pred_total,path_tif):\n",
        "  for i in range(len(test_images_filenames)):\n",
        "    \n",
        "    im_sfondo=Image.open('black_2048.jpg')\n",
        "    im_sito = Image.open(path_pred+test_images_filenames[i]+'.png')\n",
        "    \n",
        "    newsize = (1024, 1024)\n",
        "    im_sito = im_sito.resize(newsize)\n",
        "    x_min=int(name2tras[test_images_filenames[i]][0])\n",
        "    x_max=(int(name2tras[test_images_filenames[i]][0])+1024)\n",
        "    y_min=int(name2tras[test_images_filenames[i]][1])\n",
        "    y_max=(int(name2tras[test_images_filenames[i]][1])+1024)\n",
        "    im_sfondo.paste(im_sito, (x_min, y_min,x_max,y_max))\n",
        "    im_sfondo = im_sfondo.save(path_pred_total+test_images_filenames[i]+'.png')\n",
        "    if(\"neg\" in test_images_filenames[i]):\n",
        "      x_centroide=float(nameneg2Centroid[test_images_filenames[i]][0])\n",
        "      y_centroide=float(nameneg2Centroid[test_images_filenames[i]][1])\n",
        "    else:\n",
        "      x_centroide=float(namesite2Centroid[test_images_filenames[i]][0])\n",
        "      y_centroide=float(namesite2Centroid[test_images_filenames[i]][1])\n",
        "    ovest=x_centroide-1000\n",
        "    est=x_centroide+1000\n",
        "    sud=y_centroide-1000\n",
        "    nord=y_centroide+1000\n",
        "    createTif(ovest=ovest, sud=sud, est=est, nord=nord,\n",
        "              patin=path_pred_total+test_images_filenames[i]+'.png',\n",
        "              patout=path_tif+test_images_filenames[i]+\".tif\")\n",
        "\n"
      ],
      "metadata": {
        "id": "R5sQpAQAicdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prende i tif files e restituisce gli shape files\n",
        "import os\n",
        "import subprocess\n",
        "from tqdm.auto import tqdm\n",
        "from gdal import gdal_contour\n",
        "\n",
        "def convertTifToShape(tif_path,shape_path):\n",
        "  filenames = os.listdir(tif_path)\n",
        "  print(len(filenames)) #521\n",
        "  for f in tqdm(filenames):\n",
        "    print(f[:-4])\n",
        "    subprocess.run([\"gdal_contour.exe\",\"-i\",\"128\",\"-p\",tif_path+f,shape_path+f[:-4]+\".shp\"],\n",
        "                   capture_output=True,shell=True,check=False)"
      ],
      "metadata": {
        "id": "yjwqUkkaxPXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prende in input il file csv con le trasformazioni per ogni sito, \n",
        "#ritorna i nomi dei siti e un dizionario nome_sito -> trasformazioni\n",
        "def crea_trasformazione(path_csv):\n",
        "  test_sites=[]\n",
        "  name2min={}\n",
        "  count=0\n",
        "  with open(path_csv, 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in (reader):\n",
        "        if(count!=0):\n",
        "          test_sites.append(row[1])\n",
        "          name2min[row[1]]=[row[2],row[3]]\n",
        "        count+=1\n",
        "    \n",
        "  return test_sites,name2min"
      ],
      "metadata": {
        "id": "uZUWOQoGl9T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.5 Given input shapefiles and return a geojson containing for each site TP,TN,FP,FN"
      ],
      "metadata": {
        "id": "-0IVHb-nJXQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import geopandas as geopd\n",
        "from tqdm.auto import tqdm\n",
        "from shapely.geometry.multipolygon import MultiPolygon\n",
        "\n",
        "#Assegna ad ogni sito tp,tn,fp,fn in base all'intersezione della forma predetta \n",
        "#con la forma originale\n",
        "def test_for_intersection(site_id,path,verbose=False):\n",
        "    ### get shape for the original site\n",
        "    sites = geopd.read_file(PATH_SHAPE).to_crs(\"EPSG:3857\") # project to web-mercator\n",
        "    a = sites[sites.entry_id == site_id][[\"entry_id\",\"geometry\"]]\n",
        "    \n",
        "    if verbose: print('Loading Contours')\n",
        "    b = geopd.read_file(path+site_id+\".shp\").set_crs(\"EPSG:3857\")\n",
        "    b.geometry = b.geometry.convex_hull\n",
        "    b[\"entry_id\"] = \"pred\"\n",
        "    \n",
        "    if verbose: \n",
        "        print(\"number of features:\",len(b))\n",
        "        print(b)\n",
        "        \n",
        "    if len(b) > 1: # if there is more than one shape\n",
        "        b[\"geometry\"] = MultiPolygon([feature for feature in b[\"geometry\"]])\n",
        "        b = b[:1].copy()\n",
        "        if verbose: \n",
        "            print(b)\n",
        "            b.plot()\n",
        "    # negs should have no geometry\n",
        "    if len(b) == 0 and site_id.startswith(\"neg\"):\n",
        "        if verbose: print(\"good neg\")\n",
        "        return \"TN\",site_id,None\n",
        "    \n",
        "    # if neg has geometry then FP\n",
        "    elif len(b) > 0 and site_id.startswith(\"neg\"):\n",
        "        if verbose: print(\"false positive\")\n",
        "        return \"FP\",site_id,b.iloc[0][\"geometry\"] #False\n",
        "    \n",
        "    # if no geometry and not neg then FN. use a.geometry for use in QGIS\n",
        "    elif len(b) == 0 and not site_id.startswith(\"neg\"):\n",
        "        if verbose: print(\"false negative\")\n",
        "        return \"FN\",site_id, a.iloc[0][\"geometry\"]\n",
        "    \n",
        "    # compute intersection\n",
        "    if ~b.iloc[0].geometry.is_valid:\n",
        "        b.geometry = b.geometry.buffer(0)\n",
        "    intersects = a.iloc[0][\"geometry\"].intersects(b.iloc[0][\"geometry\"])\n",
        "    if verbose:\n",
        "        c = pd.concat([a,b])\n",
        "        # print(c)\n",
        "        c.plot(column=\"entry_id\",legend=True,figsize=(5,5),cmap=\"Set3\")\n",
        "        print(\"INTERSECTION: \", intersects)\n",
        "        \n",
        "    if intersects: # right geometry\n",
        "        return \"TP\",site_id,b.iloc[0][\"geometry\"]\n",
        "    else: # wrong geometry\n",
        "        return \"FP\",site_id,b.iloc[0][\"geometry\"]"
      ],
      "metadata": {
        "id": "NFGZZCWUGr7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as geopd\n",
        "#prende in input gli shapefile dei siti e ritorna un geojson \n",
        "#contenente id,nome sito, geometria e valore tra tp,tn,fp,fn\n",
        "def convertShapeToGeojson(testset,path_in,path_out):\n",
        " res = {\"index\":[],\"entry_id\":[],\"geometry\":[],\"cat\":[],}\n",
        " indice=0\n",
        " for sito in testset:\n",
        "    cat,eid,geom = test_for_intersection(sito,path_in,verbose=False)\n",
        "    res[\"index\"].append(indice)\n",
        "    res[\"entry_id\"].append(eid)\n",
        "    res[\"geometry\"].append(geom)\n",
        "    res[\"cat\"].append(cat)\n",
        "    indice+=1\n",
        " res_df = geopd.GeoDataFrame(res)\n",
        " res_df = res_df.set_index(\"index\")\n",
        " res_df.to_file(path_out, driver='GeoJSON',crs=\"EPSG:3857\")  "
      ],
      "metadata": {
        "id": "WqIYsriiHX9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.6 Main"
      ],
      "metadata": {
        "id": "hmUHRD95J-ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelli_da_comparare=['bing+corona_2k_filtrato','bing_2k_filtrato']\n",
        "PATH_SHAPE='/shapefiles/site_shape/vw_site_survey_poly.shp'\n",
        "for modello in modelli_da_comparare:\n",
        "  PATH_OUTPUT='output/'+modello+'/'\n",
        "  set_config(modello)\n",
        "  name_ckpt = os.listdir(PATH_LOG+'lightning_logs/'+modello+'/checkpoints/')[0]\n",
        "  model= ArcheoModel.load_from_checkpoint(arch=config[\"arch\"],\n",
        "                 encoder_name=config[\"encoder\"], \n",
        "                 encoder_weights=config[\"weights\"],\n",
        "                 in_channels=config['in_channels'], out_classes=1,\n",
        "                 checkpoint_path=PATH_LOG+'lightning_logs/'+modello+'/checkpoints/'+name_ckpt)\n",
        "  random.seed(config[\"random_seed\"])\n",
        "  np.random.seed(config[\"random_seed\"])\n",
        "  torch.manual_seed(config[\"random_seed\"])\n",
        "  test_images_filenames,name2tras=crea_trasformazione('trasformazioni_modello.csv')\n",
        "  images_directory=config[\"dataset_path\"]+'/train/sites'\n",
        "  masks_directory=config[\"dataset_path\"]+'/train/masks'\n",
        "  test_dataset = ArcheoDatasetModify(test_images_filenames, \n",
        "                                     images_directory, \n",
        "                                     masks_directory)\n",
        "  test_loader = DataLoader(test_dataset,batch_size=config[\"batch_size\"],\n",
        "                           shuffle=False,drop_last=False,num_workers=0,)\n",
        "\n",
        "  print(len(test_images_filenames))\n",
        "  it = iter(test_loader)\n",
        "\n",
        "\n",
        "  for j in range(len(it)):\n",
        "    batch = next(it)\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      logits = model(batch[0])\n",
        "    pr_masks = logits.sigmoid()\n",
        "    stampa_predizioni_cutoff(batch,pr_masks,j,modello,0.2)\n",
        "    stampa_predizioni_cutoff(batch,pr_masks,j,modello,0.5)\n",
        "\n",
        "  convertImageToTif(modello,0.2,PATH_OUTPUT+'pred_siti_tronc0.2/',\n",
        "                    PATH_OUTPUT+'pred_siti_centro_tronc0.2/',PATH_OUTPUT+'tif_0.2/')\n",
        "  convertImageToTif(modello,0.5,PATH_OUTPUT+'pred_siti_tronc0.5/',\n",
        "                    PATH_OUTPUT+'pred_siti_centro_tronc0.5/',PATH_OUTPUT+'tif_0.5/')\n",
        "\n",
        "  convertTifToShape(PATH_OUTPUT+'tif_0.2/',PATH_OUTPUT+'shape_0.2/')\n",
        "  convertTifToShape(PATH_OUTPUT+'tif_0.5/',PATH_OUTPUT+'shape_0.5/')\n",
        "\n",
        "  convertShapeToGeojson(test_images_filenames,PATH_OUTPUT+'shape_0.2/',PATH_OUTPUT+'preds02.geojson')\n",
        "  convertShapeToGeojson(test_images_filenames,PATH_OUTPUT+'shape_0.5/',PATH_OUTPUT+'preds05.geojson')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uB86uU4ZehpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Analysis results"
      ],
      "metadata": {
        "id": "IJaH3-WzNyMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Calculation of the confusion matrix in an automatic and adapted manner"
      ],
      "metadata": {
        "id": "T_0SyTrCU8Uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcola_matrix(preds):\n",
        "  tp= preds[preds.cat == \"TP\"]['entry_id'].shape[0]\n",
        "  tn= preds[preds.cat == \"TN\"]['entry_id'].shape[0]\n",
        "  fp= preds[preds.cat == \"FP\"]['entry_id'].shape[0]\n",
        "  fn= preds[preds.cat == \"FN\"]['entry_id'].shape[0]\n",
        "\n",
        "  matrix=[tp,tn,fp,fn]\n",
        "\n",
        "  # sono siti non visibili, quindi classificati erroneamente come tn\n",
        "  fn2tn = preds[(preds.cat == \"FN\")&(preds.correction == \"TN\")]['entry_id'].shape[0]\n",
        "\n",
        "  sites_inside_ot=preds[(preds.notes.str.contains('INSIDE OTHER',na=False)) ].shape[0]\n",
        "\n",
        "  #siti non visibili e il modello ne trova un altro esistente\n",
        "  fp2tp = preds[\n",
        "    (preds.cat == \"FP\")& ((preds.notes.str.contains('NV',na=False))| \n",
        "                        (preds.notes.str.contains('NOT VISIBLE',na=False)) |\n",
        "                        (preds.notes.str.contains('NOT VISIBILE',na=False)) |\n",
        "                        (preds.entry_id.str.contains('neg',na=False)))&\n",
        "                        (preds.notes.str.contains('INSIDE OTHER',na=False))].shape[0]\n",
        "\n",
        "  #siti visibili e il modello ne trova un altro esistente \n",
        "  fp2fn=sites_inside_ot-fp2tp\n",
        "\n",
        "  tn_a = tn + fn2tn + fp2tp\n",
        "  fn_a = fn - fn2tn + fp2fn\n",
        "  tp_a = tp + (fp2tp+fp2fn)\n",
        "  fp_a = fp - (fp2tp+fp2fn)\n",
        "\n",
        "  matrix_adj=[tp_a,tn_a,fp_a,fn_a]\n",
        "  \n",
        "  return(matrix,matrix_adj)\n",
        "\n"
      ],
      "metadata": {
        "id": "s9g4FjnPJJaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mi stampo le statistiche in termini di valori della matrice di confusione oltre a\n",
        "# precisione,recall.\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "def stampa_stats(cm,cm_adj,bing):\n",
        "  print('--------------------------------------------')\n",
        "  if(bing):\n",
        "    print(\"Stats Modello Bing 2k filtrato:\")\n",
        "  else:\n",
        "    print(\"Stats Modello Bing + Corona 2k filtrato:\")\n",
        "\n",
        "  print('---')\n",
        "\n",
        "  print(\"Valutazione automatica:\")\n",
        "  print(\"TP: \"+str(cm[0])+\" TN: \"+str(cm[1])+\" FP: \"+str(cm[2])+\" FN: \"+str(cm[3]))\n",
        "  print(\"Accuracy: \",round((cm[0]+cm[1])/(cm[0]+cm[1]+cm[2]+cm[3]),4))\n",
        "  print(\"Recall: \",round(cm[0]/(cm[0]+cm[3]),4))\n",
        "\n",
        "  print('---')\n",
        "\n",
        "  print(\"Valutazione manuale:\")\n",
        "  print(\"TP: \"+str(cm_adj[0])+\" TN: \"+str(cm_adj[1])+\" FP: \"+str(cm_adj[2])+\" FN: \"+str(cm_adj[3]))\n",
        "  print(\"Accuracy: \",round((cm_adj[0]+cm_adj[1])/(cm_adj[0]+cm_adj[1]+cm_adj[2]+cm_adj[3]),4))\n",
        "  print(\"Recall: \",round(cm_adj[0]/(cm_adj[0]+cm_adj[3]),4))\n",
        "\n",
        "  print('--------------------------------------------')"
      ],
      "metadata": {
        "id": "A_DrUrJ0ZsGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_GDMmUXk-q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "391f0ee3-9a46-490b-ff09-fa8f7a7c5a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n",
            "Stats Modello Bing 2k filtrato:\n",
            "---\n",
            "Valutazione automatica:\n",
            "TP: 228 TN: 98 FP: 70 FN: 125\n",
            "Accuracy:  0.6257\n",
            "Recall:  0.6459\n",
            "---\n",
            "Valutazione manuale:\n",
            "TP: 258 TN: 185 FP: 40 FN: 68\n",
            "Accuracy:  0.804\n",
            "Recall:  0.7914\n",
            "--------------------------------------------\n",
            "--------------------------------------------\n",
            "Stats Modello Bing + Corona 2k filtrato:\n",
            "---\n",
            "Valutazione automatica:\n",
            "TP: 209 TN: 104 FP: 57 FN: 151\n",
            "Accuracy:  0.6008\n",
            "Recall:  0.5806\n",
            "---\n",
            "Valutazione manuale:\n",
            "TP: 239 TN: 197 FP: 27 FN: 88\n",
            "Accuracy:  0.7913\n",
            "Recall:  0.7309\n",
            "--------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import geopandas as geopd\n",
        "PATH_GEOJSON_BING='/output/bing_2k_filtrato/preds05.geojson'\n",
        "PATH_GEOJSON_CORONA='/output/bing+corona_2k_filtrato/preds05.geojson'\n",
        "preds_bing = geopd.read_file(PATH_GEOJSON_BING).sort_values(\"index\").reset_index(drop=True)\n",
        "preds_corona = geopd.read_file(PATH_GEOJSON_CORONA).sort_values(\"index\").reset_index(drop=True)\n",
        "\n",
        "\n",
        "cm_bing,cm_bing_adj=calcola_matrix(preds_bing)\n",
        "stampa_stats(cm_bing,cm_bing_adj,bing=True)\n",
        "\n",
        "\n",
        "cm_corona,cm_corona_adj=calcola_matrix(preds_corona)\n",
        "stampa_stats(cm_corona,cm_corona_adj,bing=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5 Selection Area"
      ],
      "metadata": {
        "id": "_OVuUTDUGFpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.1 Create predictions for each tile"
      ],
      "metadata": {
        "id": "ckmrJv7FV3jQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_MAYSAN_DATASET='/datasets/maysan_sel_tile/'\n",
        "PATH_MAYSAN_OUTPUT='/output/maysan_sel_area/'\n",
        "PATH_MODEL_USED=PATH_LOG+'lightning_logs/bing+corona_2k_filtrato/checkpoints/epoch=19-step=2600.ckpt'"
      ],
      "metadata": {
        "id": "GAwuOOJuMSdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stampa_predizioni(ibatch,ipr_masks_11,num,patout):\n",
        "  for i,(image, gt_mask, masks_11, fn) in enumerate(zip(ibatch[0], ibatch[1], ipr_masks_11, ibatch[2])):\n",
        "\n",
        "    masks_11 = masks_11.numpy().squeeze()\n",
        "    plt.imsave(patout+'pred_magma_v1/'+ fn[:-4]+'.png',masks_11,cmap=\"magma\", vmin=0.0, vmax=1.0)\n",
        "    plt.imsave(patout+'pred_grey_v1/'+ fn[:-4]+'.png',masks_11,cmap=\"Greys\", vmin=0.0, vmax=1.0)\n",
        "   "
      ],
      "metadata": {
        "id": "Ymw6DzvxvQXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames_test_maysan = np.asarray(list(sorted(os.listdir(PATH_MAYSAN_DATASET+'sites'))))\n",
        "config['corona_path']=PATH_MAYSAN_DATASET+'corona_v1/'\n",
        "transform_maysan=A.Compose([A.Resize(512, 512),A.pytorch.ToTensorV2(),],\n",
        "                           additional_targets={'image_corona': 'image'})\n",
        "test_dataset_maysan = ArcheoDataset(filenames_test_maysan, PATH_MAYSAN_DATASET+'sites/', \n",
        "                                    PATH_MAYSAN_DATASET+'masks/', transform=transform_maysan)\n",
        "test_loader_maysan = DataLoader(test_dataset_maysan,batch_size=config[\"batch_size\"], \n",
        "                                shuffle=False,drop_last=False,num_workers=0,)\n",
        "model = ArcheoModel.load_from_checkpoint(arch=config[\"arch\"],\n",
        "                 encoder_name=config[\"encoder\"], \n",
        "                 encoder_weights=config[\"weights\"],\n",
        "                 in_channels=6, out_classes=1,checkpoint_path=PATH_MODEL_USED)\n",
        "\n",
        "random.seed(config[\"random_seed\"])\n",
        "np.random.seed(config[\"random_seed\"])\n",
        "torch.manual_seed(config[\"random_seed\"])\n",
        "\n",
        "it_maysan=iter(test_loader_maysan)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "for i in range(len(it_maysan)):\n",
        "  batch = next(it_maysan)\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    logits = model(batch[0])\n",
        "  pr_masks = logits.sigmoid()\n",
        "  stampa_predizioni(batch,pr_masks,i,PATH_MAYSAN_OUTPUT)\n"
      ],
      "metadata": {
        "id": "0agFYumlGUnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.2 Assembles the total image of the selection area"
      ],
      "metadata": {
        "id": "UjqZMMcmWAnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crea_righe(imm_size,l_x,l_y,fn,resize=False,num_res=256,format=\".png\"):\n",
        "  righe=[]\n",
        "  altezza=1\n",
        "  if(resize==True):\n",
        "    image_tot = Image.open(fn+\"1\"+format).resize((num_res,num_res))\n",
        "  else:\n",
        "    image_tot = Image.open(fn+\"1\"+format)\n",
        "  for i in range(2,l_x*l_y+1):\n",
        "    if((i-1)%l_x==0):\n",
        "      if(resize==True):\n",
        "        image_tot=Image.open(fn+str(i)+format).resize((num_res,num_res))\n",
        "      else:\n",
        "        image_tot=Image.open(fn+str(i)+format)\n",
        "    else:\n",
        "      if(resize==True):\n",
        "        image_open=Image.open(fn+str(i)+format).resize((num_res,num_res))\n",
        "      else:\n",
        "        image_open=Image.open(fn+str(i)+format)\n",
        "      new_image = Image.new('RGB',(imm_size*l_x, imm_size))\n",
        "      new_image.paste(image_tot,(0,0))\n",
        "      posizione=i%l_x\n",
        "      if(posizione==0):\n",
        "        posizione=l_x\n",
        "      new_image.paste(image_open,(imm_size*(posizione-1),((altezza-1)*image_open.size[1])))\n",
        "      image_tot=new_image\n",
        "      if(posizione==l_x):righe.append(image_tot)\n",
        "  return righe\n",
        "\n",
        "def crea_immagine(righ,dim,l_x,l_y,nome):\n",
        "  imm_totale = Image.new('RGB',(l_x*dim, l_y*dim))\n",
        "  x=-dim\n",
        "  for i in reversed(range(len(righ))):\n",
        "    x+=dim\n",
        "    imm_totale.paste(righ[i],(0,x))\n",
        "  imm_totale.save(PATH_MAYSAN_OUTPUT+nome+'.jpg')"
      ],
      "metadata": {
        "id": "qq2DYnpepMBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "f = open('coor_maysan_1000.json')\n",
        "data = json.load(f)\n",
        "spost=data[1]['cx']-data[0]['cx']\n",
        "ovest=int(data[0]['cx']-spost/2)\n",
        "sud=int(data[0]['cy']-spost/2)\n",
        "nord=int(data[len(data)-1]['cy']+(spost/2))\n",
        "num_righe=int((nord-sud)/spost)\n",
        "num_colonne=int(len(data)/num_righe)\n",
        "est=int(data[num_colonne-1]['cx']+spost/2)\n",
        "\n",
        "\n",
        "righe=crea_righe(512,num_colonne,num_righe,PATH_MAYSAN_OUTPUT+'pred_magma_v1/')\n",
        "righe1=crea_righe(512,num_colonne,num_righe,PATH_MAYSAN_OUTPUT+'pred_grey_v1/')\n",
        "crea_immagine(righe,512,num_colonne,num_righe,\"imm_tot_magma_v1\")\n",
        "crea_immagine(righe1,512,num_colonne,num_righe,\"imm_tot_grey_v1\")\n",
        "createTif(ovest,sud,est,nord,PATH_MAYSAN_OUTPUT+\"imm_tot_magma_v1.jpg\",\n",
        "          PATH_MAYSAN_OUTPUT+\"imm_tot_magma_v1.tif\")\n",
        "createTif(ovest,sud,est,nord,PATH_MAYSAN_OUTPUT+\"imm_tot_grey_v1.jpg\",\n",
        "          PATH_MAYSAN_OUTPUT+\"imm_tot_grey_v1.tif\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VmCZ89aHsdBQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}